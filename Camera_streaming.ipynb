{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python  > /dev/null\n",
    "!pip3 install albumentations > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-494cc78471d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m#VIDEO_PATH = \"car_2.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m#VIDEO_PATH = \"car3.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mshow_webcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmirror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-494cc78471d4>\u001b[0m in \u001b[0;36mshow_webcam\u001b[0;34m(mirror)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my webcam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# esc to quit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "\n",
    "# Set Variable\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Variables\n",
    "BOX_COLOR = (0, 0, 225) # Red\n",
    "BOX_THICKESS = 5\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "TEXT_SIZE = 0.9\n",
    "TEXT_FONT = 0\n",
    "IMG_SIZE = (200, 200)\n",
    "category_id_to_name = { 1: \"dent\", 2: \"broken_glass\", 3: \"deflated_wheel\", 4: \"scratch\", 5: \"broken_headlight\"}\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_training_augmentation(_src, _bboxes, _category_id, _size):\n",
    "    transform = a.Compose([a.Resize(_size[0], _size[1])], bbox_params=a.BboxParams(format='coco', label_fields=['category_id']))\n",
    "    return transform(image=_src, bboxes=_bboxes, category_id=_category_id)['bboxes']\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)\n",
    "\n",
    "def show_webcam(mirror=False):\n",
    "    model = torch.load(PATH, map_location='cpu')\n",
    "    model.eval()\n",
    "    cam = cv.VideoCapture(VIDEO_PATH)\n",
    "    frame_exist = cam.isOpened()\n",
    "    frame_id = -1\n",
    "    last_bboxes = []\n",
    "    while frame_exist:\n",
    "        frame_id += 1\n",
    "        frame_exist, img = cam.read()\n",
    "        if not frame_exist:\n",
    "            break\n",
    "\n",
    "        if mirror: \n",
    "            img = cv.flip(img, 1)\n",
    "\n",
    "        if frame_id % FPS == 0:\n",
    "            # If there any nessesarity to conver so much times?\n",
    "            #img_ = torch.tensor(img)\n",
    "            #img_TORCH = tensor_to_image(img_)\n",
    "            #img_T = transform(img_TORCH)\n",
    "            img_T = transform(img)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = model([img_T])\n",
    "            \n",
    "            if len(prediction[0][\"labels\"]) > 0:\n",
    "                last_bboxes.clear()\n",
    "                h = 0\n",
    "                for left, top, right, bottom in prediction[0]['boxes']:\n",
    "                    if float(prediction[0][\"scores\"][h]) > TOLERANCE:\n",
    "                        left, top, right, bottom = int(left), int(top), int(right), int(bottom)\n",
    "                        last_bboxes.append( (left, top, right, bottom, category_id_to_name.get(int(prediction[0]['labels'][h])) ))\n",
    "                        cv.rectangle(img,(left,top),(right, bottom), BOX_COLOR, BOX_THICKESS)\n",
    "                        cv.putText(img, category_id_to_name.get(int(prediction[0]['labels'][h])), \\\n",
    "                                            (right+10, bottom), TEXT_FONT, TEXT_SIZE, TEXT_COLOR)\n",
    "                    h += 1\n",
    "            else:\n",
    "                last_bboxes.clear()\n",
    "        elif len(last_bboxes) and STREAMING:\n",
    "            for left, top, right, bottom, name in last_bboxes:\n",
    "                cv.rectangle(img,(left,top),(right, bottom), BOX_COLOR, BOX_THICKESS)\n",
    "                cv.putText(img, name, (right+10, bottom), TEXT_FONT, TEXT_SIZE, TEXT_COLOR)\n",
    "        \n",
    "        cv.imshow('my webcam', img)\n",
    "\n",
    "        if cv.waitKey(1) == 27: \n",
    "            break  # esc to quit\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "STREAMING = True\n",
    "FPS = 10\n",
    "TOLERANCE = 0.7\n",
    "VIDEO_PATH = \"IMG_5367.MOV\"\n",
    "#VIDEO_PATH = \"testcam.png\"\n",
    "#VIDEO_PATH = \"car.jpeg\"\n",
    "#VIDEO_PATH = \"carb.jpg\"\n",
    "#VIDEO_PATH = \"car_2.jpg\"\n",
    "#VIDEO_PATH = \"car3.jpg\"\n",
    "show_webcam(mirror=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbc59c1602769476583de30dcfaf94a717f95996dfb09063277734c10faa726c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
