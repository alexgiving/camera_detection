{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 160>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39m0\u001b[39m]\n\u001b[1;32m    159\u001b[0m \u001b[39m#show_webcam(VIDEO_PATH=path)           # Main function\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m show_webcam(VIDEO_PATH\u001b[39m=\u001b[39;49mpath, MIRROR\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, SHOW_FPS\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, STREAMING\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, RESIZE\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, CONSOLE\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mshow_webcam\u001b[0;34m(MIRROR, VIDEO_PATH, SHOW_FPS, STREAMING, RESIZE, CONSOLE)\u001b[0m\n\u001b[1;32m    134\u001b[0m         cv\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mmy webcam\u001b[39m\u001b[39m'\u001b[39m, img)\n\u001b[1;32m    136\u001b[0m     frame_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mif\u001b[39;00m cv\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m==\u001b[39m \u001b[39m27\u001b[39m: \n\u001b[1;32m    138\u001b[0m         \u001b[39mbreak\u001b[39;00m  \u001b[39m# esc to quit\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m CONSOLE \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps_history):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import albumentations as A\n",
    "import time\n",
    "import sys \n",
    "\n",
    "\n",
    "# Set Variable\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Variables\n",
    "BOX_COLOR = (0, 0, 225) # Red\n",
    "BOX_THICKESS = 5\n",
    "TEXT_COLOR = (100, 255, 0)\n",
    "TEXT_FONT = 0\n",
    "IMG_SIZE = (200, 200)\n",
    "category_id_to_name = { 1: \"dent\", 2: \"broken_glass\", 3: \"deflated_wheel\", 4: \"scratch\", 5: \"broken_headlight\"}\n",
    "transform_to_tensor = T.ToTensor()\n",
    "\n",
    "# UNUSED\n",
    "def get_training_augmentation(_src, _bboxes, _category_id, _size):\n",
    "    transform = A.Compose([A.Resize(_size[0], _size[1])], bbox_params=A.BboxParams(format='coco', label_fields=['labels']))\n",
    "    return transform(image=_src, bboxes=_bboxes, category_id=_category_id)['bboxes']\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)\n",
    "\n",
    "\n",
    "def draw_box(_image, _left, _top, _right, _bottom, _name):\n",
    "    TEXT_SIZE = round(get_optimal_font_scale(_name, _image.shape[1])/2)\n",
    "    cv.rectangle(_image, (_left, _top), (_right, _bottom), BOX_COLOR, BOX_THICKESS)\n",
    "    cv.putText(_image, _name, (_right+10, _bottom), TEXT_FONT, TEXT_SIZE, TEXT_COLOR)\n",
    "    return _image\n",
    "\n",
    "\n",
    "def get_optimal_font_scale(text, width):\n",
    "    for scale in range(60, 0, -1):\n",
    "        textSize = cv.getTextSize(text, fontFace=cv.FONT_HERSHEY_DUPLEX, fontScale=scale/10, thickness=1)\n",
    "        if (textSize[0][0] <= width):\n",
    "            return scale/10\n",
    "    return 1\n",
    "\n",
    "\n",
    "def get_image_with_boxes(img=None, prediction=None, resize=False, fx=0, fy=0, tolerance=0):\n",
    "    h = 0\n",
    "    array_bbox = []\n",
    "    for left, top, right, bottom in prediction[0]['boxes']:\n",
    "        if float(prediction[0][\"scores\"][h]) > tolerance:\n",
    "            left, top, right, bottom = int(left), int(top), int(right), int(bottom)\n",
    "            name = category_id_to_name.get(int(prediction[0]['labels'][h]))\n",
    "            if resize:\n",
    "                assert(fx != 0)\n",
    "                assert(fy != 0)\n",
    "                left = int(round(left * fx))\n",
    "                top  = int(round(top * fy))\n",
    "                right = round(right * fx)\n",
    "                bottom = int(round(bottom * fy))\n",
    "            array_bbox.append( (left, top, right, bottom, name) )                  # Save boxes\n",
    "            img = draw_box(img, left, top, right, bottom, name)\n",
    "        h += 1\n",
    "    return img, array_bbox\n",
    "\n",
    "\n",
    "def show_webcam(MIRROR=False, VIDEO_PATH=0, SHOW_FPS=False, STREAMING=False, RESIZE=False, CONSOLE=False):\n",
    "    model = torch.load(PATH, map_location=device).eval()\n",
    "    cam = cv.VideoCapture(VIDEO_PATH)\n",
    "    frame_exist = cam.isOpened()\n",
    "    frame_id = 0\n",
    "    last_bboxes = []\n",
    "    fps_history = []\n",
    "    FX = 1\n",
    "    FY = 1\n",
    "\n",
    "    prev_frame_time = 0\n",
    "    new_frame_time = 0\n",
    "\n",
    "    while frame_exist:\n",
    "        frame_exist, img = cam.read()\n",
    "        new_frame_time = time.time()\n",
    "\n",
    "        if not frame_exist: break\n",
    "        if MIRROR: img = cv.flip(img, 1)\n",
    "\n",
    "        '''\n",
    "        Optimization trick:\n",
    "        Nearest frames in camera or video streaming have the same objects which are approximately placed closely\n",
    "        We can skip some next frames from predictor and move the boxes from previous frame to increase FPS in STREAMING mode\n",
    "        Skipped frames output without latency\n",
    "        '''\n",
    "        FLAG = False\n",
    "        if frame_id % FRAME_PRED == 0:\n",
    "\n",
    "            if RESIZE:\n",
    "                FX = IMG_SIZE[0] / img.shape[1]\n",
    "                FY = IMG_SIZE[1] / img.shape[0]\n",
    "                debug_img = cv.resize(img, (0,0), fx=FX, fy=FY)\n",
    "            else:\n",
    "                debug_img = img\n",
    "\n",
    "            FLAG = True\n",
    "            with torch.no_grad(): prediction = model([transform_to_tensor(debug_img).to(device)])\n",
    "\n",
    "            last_bboxes.clear()\n",
    "            if len(prediction[0][\"labels\"]) > 0:  # Predictor find any class of damage?\n",
    "                img, last_bboxes = get_image_with_boxes(img=img, prediction=prediction, resize=RESIZE, fx=1/FX, fy=1/FY, tolerance=TOLERANCE)\n",
    "\n",
    "        elif STREAMING and len(last_bboxes):\n",
    "            for left, top, right, bottom, name in last_bboxes:\n",
    "                img = draw_box(img, left, top, right, bottom, name)\n",
    "        \n",
    "        if (FLAG or STREAMING) and SHOW_FPS:\n",
    "            fps = 1/(new_frame_time-prev_frame_time)\n",
    "            TEXT_SIZE = round(get_optimal_font_scale(f\"FPS: 000000\", img.shape[1])/2)\n",
    "            prev_frame_time = new_frame_time\n",
    "            fps_history.append(int(fps))\n",
    "            if not CONSOLE:\n",
    "                cv.putText(img, f\"FPS: { sum(fps_history)/len(fps_history):0.2f}\", (7, 70), TEXT_FONT, TEXT_SIZE, TEXT_COLOR, 3, cv.LINE_AA)\n",
    "        \n",
    "\n",
    "        if not CONSOLE and (FLAG or STREAMING):\n",
    "            cv.imshow('my webcam', img)\n",
    "\n",
    "        frame_id += 1\n",
    "        if cv.waitKey(1) == 27: \n",
    "            break  # esc to quit\n",
    "    if CONSOLE and len(fps_history):\n",
    "        print(f\"Average FPS: { sum(fps_history)/len(fps_history):0.2f}\")\n",
    "    cv.destroyAllWindows()\n",
    "    return \n",
    "\n",
    "\n",
    "FRAME_PRED = 10                     # FPS of Prediction pipeline\n",
    "TOLERANCE = 0.4                     # Predictors confidence of class\n",
    "PATH = \"include/model_4.pt\"        # Path to predictor model\n",
    "\n",
    "list = [\"data/IMG_5367.MOV\",\n",
    "        \"data/testcam.png\",\n",
    "        \"data/car.jpeg\",\n",
    "        \"data/carb.jpg\",\n",
    "        \"data/car_2.jpg\",\n",
    "        \"data/car3.jpg\",\n",
    "        0                     # Camera\n",
    "]\n",
    "path = list[0]\n",
    "\n",
    "#show_webcam(VIDEO_PATH=path)           # Main function\n",
    "show_webcam(VIDEO_PATH=path, MIRROR=False, SHOW_FPS=True, STREAMING=True, RESIZE=False, CONSOLE=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perf tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import albumentations as A\n",
    "import time\n",
    "import sys \n",
    "\n",
    "\n",
    "# Set Variable\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Variables\n",
    "BOX_COLOR = (0, 0, 225) # Red\n",
    "BOX_THICKESS = 5\n",
    "TEXT_COLOR = (100, 255, 0)\n",
    "TEXT_FONT = 0\n",
    "IMG_SIZE = (200, 200)\n",
    "category_id_to_name = { 1: \"dent\", 2: \"broken_glass\", 3: \"deflated_wheel\", 4: \"scratch\", 5: \"broken_headlight\"}\n",
    "transform_to_tensor = T.Compose([T.ToTensor()])\n",
    "\n",
    "def perf_test(resize=False):\n",
    "    import time\n",
    "    list_time = []\n",
    "    array = [\"data/car3.jpg\", \"data/car_2.jpg\", \"data/carb.jpg\", \"data/car.jpeg\", \"data/testcam.png\"]\n",
    "    iters = 50\n",
    "\n",
    "    for i in range(iters):\n",
    "        path = array[i%len(array)]\n",
    "        tic = time.perf_counter()\n",
    "        show_webcam(VIDEO_PATH=path, RESIZE=resize)\n",
    "        toc = time.perf_counter()\n",
    "        list_time.append((tic, toc))\n",
    "\n",
    "    average_time = 0\n",
    "    for pair in list_time:\n",
    "        average_time += pair[1] - pair[0]\n",
    "\n",
    "    print(f\"Perf demo test: {average_time/iters:0.4f} average seconds\")\n",
    "\n",
    "\n",
    "def perf_model_test(_path, crop=False):\n",
    "    import time\n",
    "    list_time = []\n",
    "    model = torch.load(_path, map_location=device)\n",
    "    model.eval()\n",
    "    array = [\"data/car3.jpg\", \"data/car_2.jpg\", \"data/carb.jpg\", \"data/car.jpeg\", \"data/testcam.png\"]\n",
    "    iters = 25\n",
    "\n",
    "    for i in range(iters):\n",
    "        cam = cv.VideoCapture(array[i%len(array)])\n",
    "        _, img = cam.read()\n",
    "        img = cv.resize(img, (1920, 1080))\n",
    "        if crop:\n",
    "            FX = 500 / img.shape[1]\n",
    "            FY = 500 / img.shape[0]\n",
    "            img = cv.resize(img, (0,0), fx=FX, fy=FY)\n",
    "        img_T = transform_to_tensor(img)\n",
    "        with torch.no_grad():\n",
    "            tic = time.perf_counter()\n",
    "            prediction = model([img_T])\n",
    "            toc = time.perf_counter()\n",
    "            list_time.append((tic, toc))\n",
    "\n",
    "    average_time = 0\n",
    "    for pair in list_time:\n",
    "        average_time += pair[1] - pair[0]\n",
    "    print(f\"Perf model test: {average_time/iters:0.4f} average seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf demo test: 0.8717 average seconds\n",
      "Perf demo test: 0.6596 average seconds\n"
     ]
    }
   ],
   "source": [
    "perf_test(resize=False)\n",
    "perf_test(resize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf model test: 0.3375 average seconds\n",
      "Perf model test: 1.2306 average seconds\n",
      "Perf model test: 0.1300 average seconds\n",
      "Perf model test: 0.3363 average seconds\n"
     ]
    }
   ],
   "source": [
    "perf_model_test(\"include/model_2.pt\", crop=False)\n",
    "perf_model_test(\"include/model_3.pt\", crop=False)\n",
    "perf_model_test(\"include/model_4.pt\", crop=False)\n",
    "perf_model_test(\"include/model_70.pt\", crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf model test: 0.2597 average seconds\n",
      "Perf model test: 0.7767 average seconds\n",
      "Perf model test: 0.1108 average seconds\n",
      "Perf model test: 0.2385 average seconds\n"
     ]
    }
   ],
   "source": [
    "perf_model_test(\"include/model_2.pt\", crop=True)\n",
    "perf_model_test(\"include/model_3.pt\", crop=True)\n",
    "perf_model_test(\"include/model_4.pt\", crop=True)\n",
    "perf_model_test(\"include/model_70.pt\", crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbc59c1602769476583de30dcfaf94a717f95996dfb09063277734c10faa726c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
